\documentclass{article}

\usepackage{graphicx,booktabs,array}
% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
% \usepackage{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[]{neurips_2019}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}

%added
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabu}
\tabulinesep=2.0mm
\usepackage{float}
\usepackage{rotating}
% \usepackage{adjustbox}


% \usepackage[backend=biber, style=numeric]{biblatex}


% \addbibresource{Bibliography.bib} %Imports bibliography file
% to avoid loading the natbib package, add option nonatbib:
    % \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage[dvipsnames]{xcolor}
\usepackage[normalem]{ulem}
\newif{\ifhidecomments}


\title{Supplementary for: [Re] AdaBelief Optimizer, Adapting Stepsizes by the
Belief in Observed Gradients}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  David S.~Hippocampus\thanks{Use footnote for providing further information
    about author (webpage, alternative address)---\emph{not} for acknowledging
    funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle




% \begin{table}[htbp]
%     \begin{center}
%     \begin{tabular}{ccc}
    
%     \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5a.png} & \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5b.png}  & \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5c.png} \\
    
    
%     \end{tabular}
%  %                 
%     \caption{\label{tab:LSTM_PTB_Plots} Left to right: perplexity ([$\mu \pm \sigma$]) on Penn Treebank for 1,2,3-layer LSTM. Lower is better}
%     \end{center}
% \end{table}


% \begin{figure}[htbp]
% 	\centering
% 		\includegraphics[width=\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/fig_lstm.png}
% 	\caption[Mask color palette]{Mask color palette}
% 	\label{fig:Color_palette}
% \end{figure}


% LSTM train ppl
\section{Experiments on language modeling}
\label{sec:LSTM}
\subsection{Penn Treebank dataset}
We ran experiments using LSTM \cite{LSTM} models on Penn Treebank dataset \cite{PTB} and plot train perplexities (Fig. \ref{table:LSTM_train}) and test perplexities (Fig. \ref{table:LSTM_test}) for 3 independent runs.

\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5atrain.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5btrain.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5ctrain.png} \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Left to right: Train perplexity  $([\mu \pm \sigma])$ on Penn Treebank \ for 1,2,3-layer LSTM } \label{table:LSTM_train}
    \end{center}
\end{table}

% LSTM test ppl
\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5atest.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5btest.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5ctest.png} \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Left to right: Test perplexity  $([\mu \pm \sigma])$ on Penn Treebank  for 1,2,3-layer LSTM} \label{table:LSTM_test}
    \end{center}
\end{table}

\subsection{WikiText-2 dataset}
We perform experiments on WikiText-2 dataset \cite{WikiText_2} using LSTM models with Adam \cite{Adam} and AdaBelief \cite{zhuang_adabelief_2020} as optimizers. Train perplexities (Fig. \ref{table:LSTM_train_WT2}) and test perplexities (Fig. \ref{table:LSTM_test_WT2}) are reported for 3 independent runs.

% WT-2 LSTM train ppl
\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/WT-2_one_layertrain.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/WT-2_two_layertrain.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/WT-2_three_layertrain.png} \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Left to right: Train perplexity  $([\mu \pm \sigma])$ on WikiText-2 for 1,2,3-layer LSTM} \label{table:LSTM_train_WT2}
    \end{center}
\end{table}

% WT-2 LSTM test ppl
\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/WT-2_one_layertrain.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/WT-2_two_layertrain.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/WT-2_three_layertrain.png} \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Left to right: Test perplexity  $([\mu \pm \sigma])$ on WikiText-2 for 1,2,3-layer LSTM} \label{table:LSTM_test_WT2}
    \end{center}
\end{table}

% \begin{table}[htbp]
%     \begin{center}
%     \begin{tabular}{ccc}
    
%     \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5a.png} & \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5b.png}  & \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5c.png} \\
    
    
%     \end{tabular}
%  %                 
%     \captionof{figure}{I don't want a table: My way} \label{table:mul}
%     \end{center}
% \end{table}

% \begin{table}[htbp]
%     \begin{center}
%     \begin{tabular}{ccc}
    
%     \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5a.png} & \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5b.png}  & \includegraphics[width=0.31\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_trimmed_plot/Figure_5c.png} \\
    
    
%     \end{tabular}
%  %                 
%     \captionof{figure}{I don't want a table: My way} \label{table:mul}
%     \end{center}
% \end{table}


% \begin{table}[tbp]
% \begin{tabular}{ c  c }
% % \hline
% \includegraphics[scale=0.380]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5a.png} &
% \includegraphics[scale=0.380]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5a.png} \\
% % \hline
% (a) & (b) \\
% % \hline
% \multicolumn{2}{ c }{\includegraphics[scale=0.50]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5a.png}} \\
% % \hline
% \multicolumn{2}{ c }{(c)} \\
% % \hline
% \end{tabular}
% \caption[Visualization of x-vectors from CALLHOME recordings]{\textbf{Experiment 3(b)}: Visualization of x-vectors from CALLHOME's recordings extracted using the PyTDNN fine-tuned on a subset of telephony data. (a) Recording \textbf{iaaa}, 2 speakers with 70\%-30\% speech duration. (b) Recording \textbf{iamo}, 2 speakers, 50\%-50\% speech duration. (c) Recording \textbf{iaqs}, 3 speakers, 20\%-30\%-50\% speech duration.}
% \label{table:callhome_viz}
% \end{table}



\section{Experiments on image classification}
\label{sec:Image_classification}

\subsection{Cifar10 and Cifar100}
We ran experiments on Cifar10 and Cifar100 on VGG11 \cite{VGG}, ResNet34 \cite{Resnet}, DenseNet \cite{Densenet} architectures. We report train accuracies (Fig. \ref{table:CIFAR10_100_train}) and test accuracies (Fig. \ref{table:CIFAR10_100_test}) for 3 independent runs.

\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4aTrain.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4bTrain.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4cTrain.png} \\
    (a) VGG11 on Cifar10 & (b) Resnet34 on Cifar10 & (c) Densenet121 on Cifar10 \\
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4dTrain.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4eTrain.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4fTrain.png} \\
    (d) VGG11 on Cifar100 & (e) Resnet34 on Cifar100 & (f) Densenet121 on Cifar100 \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Train accuracy $([\mu \pm \sigma])$ on Cifar 10 and Cifar 100.} \label{table:CIFAR10_100_train}
    \end{center}
\end{table}

% test acc cifar
\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4atest.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4btest.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4ctest.png} \\
    (a) VGG11 on Cifar10 & (b) Resnet34 on Cifar10 & (c) Densenet121 on Cifar10 \\
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4dtest.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4etest.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/CIFAR_plots/Figure_4ftest.png} \\
    (d) VGG11 on Cifar100 & (e) Resnet34 on Cifar100 & (f) Densenet121 on Cifar100 \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Test accuracy $([\mu \pm \sigma])$ on Cifar 10 and Cifar 100.} \label{table:CIFAR10_100_test}
    \end{center}
\end{table}

\section{Experiments on generative modeling}
\label{sec:GANs}
\subsection{WGAN}
We run experiments on Cifar10 dataset using WGAN \cite{WGAN} for the task of generative modelling. We present a collage of fake images output by WGAN for each optimizer (Fig. \ref{table:WGAN_fake_all}). 
\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_adabelief.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_adabound.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_adam.png} \\
    (a) AdaBelief & (b) AdaBound & (c) Adam \\
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_msvag.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_fromage.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_radam.png} \\
    (d) MSVAG & (e) Fromage & (f) RAdam \\
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_rmsprop.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_yogi.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_sgd.png} \\
    (g) RMSProp & (h) Yogi & (i) SGD \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Fake samples from WGAN trained with different optimizers} \label{table:WGAN_fake_all}
    \end{center}
\end{table}

\subsection{WGAN-GP}
We run experiments on Cifar10 dataset using WGAN-GP \cite{WGAN-GP}. We present a collage of fake images output by WGAN for each optimizer (Fig. \ref{table:WGAN-GP_fake_all}). Fig. \ref{WGAN-GP_fake_all_partials} shows the images obtained from training Padam \cite{padam} using different partials. 
\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_adabelief.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_adabound.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_adam.png} \\
    (a) AdaBelief & (b) AdaBound & (c) Adam \\
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_msvag.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_fromage.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_radam.png} \\
    (d) MSVAG & (e) Fromage & (f) RAdam \\
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_rmsprop.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_yogi.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_sgd.png} \\
    (g) RMSProp & (h) Yogi & (i) SGD \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Fake samples from WGAN-GP trained with different optimizers} \label{table:WGAN-GP_fake_all}
    \end{center}
\end{table}



% \begin{table}[h]
% 	\centering
% 	\begin{tabu} to \textwidth {  X[c,m]  X[c,m]  X[c,m]  }
		
% 		\includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_Padam_0.0625.png} &
% 		\includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_Padam_0.125.png} &
% 		\includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_Padam_0.2.png}  \\
% 		(a) $p=0.0625$ & (b) $p=0.125$ & (c) $p=0.2$ \\
% 	\end{tabu}
% 	\begin{tabu} to \textwidth {  X[c,m]  X[c,m]  }

% 		\includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_Padam_0.25.png} &
% 		\includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN_Fake_Images/Figure_7_Padam_0.4.png} \\
% 		(d) $p=0.25$ & (e) $p=0.4$
% 	\end{tabu}
% 	\vspace{2mm}
%     \captionof{figure}{Fake samples from Padam WGAN trained with different partials)} \label{table:WGAN-GP_fake_all}
% \end{table}


\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c c}
    
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/real_samples.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.125.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.2.png} \\
    (a) Real & (b) $p=0.125$ & (c) $p=0.2$ \\
    \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.0625.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.25.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.4.png} \\
    (d) $p=0.0625$ & (e) $p=0.25$ & (f) $p=0.4$ \\
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Fake samples from Padam WGAN-GP trained with different partials} \label{table:WGAN-GP_fake_all_partials}
    \end{center}
\end{table}

\section{Experiments on Reinforcement Learning}
\label{sec:RL}
\subsection{Space Invaders}
We train an agent to learn to play Space Invaders (Atari Game) using DQN \cite{DQN_RL} architecture with Adam \cite{Adam} and AdaBelief \cite{zhuang_adabelief_2020} as optimizers. Fig. \ref{table:Q_value} shows the Q value and Fig. \ref{table:Reward_value} plots the reward function against training steps.
\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c}
    
    \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/RL/Adabelief_Q.jpeg} & \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/RL/Adam_Q.jpeg}  \\ 
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Q value on RL toy experiment using different optimizer} \label{table:Q_value}
    \end{center}
\end{table}

\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{c c}
    
    \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/RL/Adabelief_Reward.jpeg} & \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/RL/Adam_Reward.jpeg}  \\ 
    \end{tabular}
    \vspace{2mm}
    \captionof{figure}{Reward function on RL toy experiment using different optimizer} \label{table:Reward_value}
    \end{center}
\end{table}


% \begin{sidewaystable}[htbp]
% \begin{adjustbox}{angle=90}

% \end{adjustbox}

% \begin{table}[htbp]
%     \begin{center}
%     \begin{tabular}{c c c}
    
%     \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/WT-2_one_layertest.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.125.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.2.png} \\
%     (a) Real & (b) $p=0.125$ & (c) $p=0.2$ \\
%     \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.0625.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.25.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.4.png} \\
%     (d) $p=0.0625$ & (e) $p=0.25$ & (f) $p=0.4$ \\
%     \end{tabular}
%     \vspace{2mm}
%     \captionof{figure}{Fake samples from Padam WGAN-GP trained with different partials} \label{table:WGAN-GP_fake_all_partials}
%     \end{center}
% \end{table}






% \begin{table}[htbp]
%     \begin{center}
%     \begin{tabular}{c c c}
    
%     \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5a_reruntest.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5b_reruntest.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5c_reruntest.png} \\
%     \end{tabular}
%     \vspace{2mm}
%     \captionof{figure}{Left to right: Test perplexity  $([\mu \pm \sigma])$ on Penn Treebank for 1,2,3-layer LSTM} \label{table:LSTM_test}
%     \end{center}
% \end{table}







% \begin{table}[htbp]
%     \begin{center}
%     \begin{tabular}{c c c}
    
%     \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5atest.png} & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5btest.png}  & \includegraphics[width=0.305\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/LSTM_plots/Figure_5ctest.png} \\
%     \end{tabular}
%     \vspace{2mm}
%     \captionof{figure}{Left to right: Test perplexity  $([\mu \pm \sigma])$ on Penn Treebank for 1,2,3-layer LSTM} \label{table:LSTM_test}
%     \end{center}
% \end{table}











% \begin{table}[h]
%   \centering
%   \begin{tabu} to \textwidth {  X[c,m]  X[c,m]  X[c,m]  }
    
%     \includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/real_samples.png} &
%     \includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.125.png} &
%     \includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.2.png}  \\
%     (a) $p=0.0625$ & (b) $p=0.125$ & (c) $p=0.2$ \\
%   \end{tabu}
%   \begin{tabu} to \textwidth {  X[c,m]  X[c,m]  X[c,m]}
%      \includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.0625.png} & \\
%     \includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.25.png} &
%     \includegraphics[scale=0.25]{Reproducibility_Challenge_2020/Reproduced_figures/WGAN-GP_Fake_Images/Figure_7_Padam_0.4.png} \\
%     (d) $p=0.0625$ (e) $p=0.25$ & (f) $p=0.4$
%   \end{tabu}
%   \vspace{2mm}
%     \captionof{figure}{Fake samples from Padam WGAN-GP trained with different partials)} \label{table:WGAN-GP-GP_fake_all}
% \end{table}


% SNGAN FID vs steps plot
% \begin{figure}[htbp]
% 	\centering
% 		\includegraphics[scale=0.5]{Reproducibility_Challenge_2020/Reproduced_figures/GAN_plots/SNGAN_FID.png}
% 	\caption[SN-GAN FID]{SN-GAN FID v/s Steps}
% 	\label{fig:SN-GAN FID}
% \end{figure}

% table with convergence epoch of each optimizer

% \section{Stability Analysis}
% \subsection{SN-GAN}
% To analyse the stability of GANs we measure the gap between generator and discriminator losses at different stages of training in SN-GAN \cite{SN-GAN} on Cifar10 dataset. We do this exercise for AdaBelief \cite{zhuang_adabelief_2020}, SGD \cite{SGD}, Adam \cite{Adam}, RMSProp \cite{RMSProp}. Figure \ref{table:gen_disc_loss_gap} highlights the difference in \textcolor{red}{red}. A higher gap is attributed to unstable training and a small gap means that the training is stable. From this we can see that the order of stability from most to least follows as: RMSProp, AdaBelief, Adam, SGD.

% \begin{table}[htbp]
%     \begin{center}
%     \begin{tabular}{c c}
%     \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/GAN_plots/Gen_Dis_Loss/SNGAN_Gen_Dis_loss_AdaBelief.png} & \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/GAN_plots/Gen_Dis_Loss/SNGAN_Gen_Dis_loss_SGD.png} \\
%     (a) AdaBelief & (b) SGD \\
%     \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/GAN_plots/Gen_Dis_Loss/SNGAN_Gen_Dis_loss_Adam.png} &
%     \includegraphics[width=0.45\textwidth]{Reproducibility_Challenge_2020/Reproduced_figures/GAN_plots/Gen_Dis_Loss/SNGAN_Gen_Dis_loss_RMSProp.png} \\ 
%     (c) Adam & (d) RMSProp \\
%     \end{tabular}
%     \vspace{2mm}
%     \captionof{figure}{SN-GAN Generator Discriminator loss after smoothing the curves with $\beta$ = 0.95} 
%     \label{table:gen_disc_loss_gap}
%     \end{center}
% % \end{sidewaystable}
% \end{table}

\section{Convergence Analysis}
\subsection{Cifar10, Cifar100, LSTM}
To understand convergence abilites of different optimizers we make use of definition <x> from the main paper. Table \ref{table:convergence_epoch} shows the convergence epoch for the different optimizer for experiments performed on Cifar10, Cifar100 using VGG11, ResNet34, DenseNet as backbones and on PTB dataset trained using LSTMs.

\begin{table}[htbp]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{c | c c c | c c c | c c c}
    \hline
    \multirow{2}{*}{\textbf{Optimizer}}& \multicolumn{3}{c|}{\textbf{CIFAR-10}} & \multicolumn{3}{c|}{\textbf{CIFAR-100}} & \multicolumn{3}{c}{\textbf{LSTM}} \\
    \cline{2-10}
    & \textbf{VGG11} & \textbf{ResNet34} & \textbf{DenseNet121} & \textbf{VGG11} & \textbf{ResNet34} & \textbf{DenseNet121} & \textbf{1 layer} & \textbf{2 layer} & \textbf{3 layer} \\
    \hline
    Adam & 164 & 161 & 163 & 181 & 160 & 161 & 117 & 160 & 166 \\
    \hline
    AdaBelief & 159 & 165 & 168 & 162 & 181 & 172 & 118 & 137 & 154 \\
    \hline
    RAdam & 163 & 176 & 162 & 180 & 169 & 180 & 110 & 106 & 107 \\
    \hline
    AdamW & 160 & 163 & 165 & 174 & 173 & 178 & 115 & 106 & 105 \\
    \hline
    Yogi & 161 & 173 & 166 & 164 & 175 & 174 & 119 & 123 & 119 \\
    \hline
    MSVAG & 159 & 179 & 163 & 176 & 170 & 166 & 130 & 125 & 119 \\
    \hline
    Fromage & 164 & 182 & 163 & 161 & 175 & 165 & 115 & 117 & 117 \\
    \hline
    AdaBound & 169 & 182 & 164 & 165 & 168 & 179 & 156 & 129 & 127 \\
    \hline
    SGD & 167 & \texttt{FTC} & 162 & \texttt{FTC} & 166 & \texttt{FTC} & 157 & 151 & 123 \\
    \hline
    Apollo & 177 & \texttt{FTC} & 174 & 186 & 172 & 179 & - & - & - \\
    \hline
    \end{tabular}}
    \vspace{2mm}
    \caption{Epoch of convergence (out of 200) for each optimizer for different experiments. \texttt{FTC} denotes \textit{failed to converge}. AdaBelief converges at epochs similar to other optimizers from Adaptive gradient family.}
    \label{table:convergence_epoch}
\end{table}


% \label{Bibliography}

% \lhead{\emph{Bibliography}} % Change the page header to say "Bibliography"
% \section*{References}
% \printbibliography
\bibliographystyle{plain}
\bibliography{supp_bibliography}



\end{document}


